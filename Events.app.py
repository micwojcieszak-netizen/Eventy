import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd

st.set_page_config(page_title="Stadium Event Finder", layout="wide")

st.title("ğŸŸï¸ Stadium Event Scout")
st.write("Wpisz nazwÄ™ areny, aby pobraÄ‡ nadchodzÄ…ce wydarzenia.")

venue = st.selectbox("Wybierz arenÄ™:", ["AO Arena (Manchester)", "Inne stadiony (w budowie)"])

def get_ao_arena_events():
    url = "https://www.ao-arena.com/events/"
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        events = []
        # Szukamy elementÃ³w na stronie AO Arena (uproszczony przykÅ‚ad)
        for item in soup.select('.event-card'): # To zaleÅ¼y od kodu strony
            title = item.select_one('.event-title').text.strip()
            date = item.select_one('.event-date').text.strip()
            events.append({"Data": date, "Wydarzenie": title})
        
        return pd.DataFrame(events)
    except Exception as e:
        return f"BÅ‚Ä…d podczas pobierania danych: {e}"

if st.button("Pobierz wydarzenia"):
    with st.spinner('ÅÄ…czenie z serwerem areny...'):
        if venue == "AO Arena (Manchester)":
            # Symulacja pobierania (scrapingu) dla demonstracji
            data = pd.DataFrame([
                {"Data": "20 Maj 2024", "Wydarzenie": "Girls Aloud"},
                {"Data": "24 Czerwiec 2024", "Wydarzenie": "Liam Gallagher"},
                {"Data": "15 Lipiec 2024", "Wydarzenie": "Stevie Nicks"}
            ])
            st.success(f"Znaleziono wydarzenia dla {venue}")
            st.table(data)
        else:
            st.warning("Ta arena nie jest jeszcze skonfigurowana.")

st.info("ğŸ’¡ Aby pobieraÄ‡ dane z kaÅ¼dej strony na Å›wiecie, musielibyÅ›my napisaÄ‡ osobne reguÅ‚y dla kaÅ¼dego adresu URL (tzw. Scrapers).")
